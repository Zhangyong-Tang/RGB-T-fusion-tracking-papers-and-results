# RGB-T fusion tracking：papers，datasets & results
A list of papers, datasets (benchmarks) and results in RGB-T fusion tracking.  
- If you think this is useful, please consider giving a star, thanks!  
- If you think some information is wrong, please fell free to contact me to correct.  
- If you think some papers are missing and you want to add, please feel free to raise an issue or contact me.  
- Contact detail: xingchen.zhang@imperial.ac.uk

## Table of Contents
- [Papers][1]
  - [Review paper][2]
  - [2021](#2021) 
  - [2020][3]
  - [2019][4]
  - [2018][5]
  - [2017][6]
  - [2016][7]
  - [Before 2016][8]
- [Datasets and benchmark][9]
  - [GTOT][10]
  - [RGBT210][11]
  - [RGBT234][12]
- [Results][13]
  - [GTOT][14]
  - [RGBT210][15]
  - [RGBT234][16]  
- [VOT-RGBT Challenge][17]
  - [2019][18]

## Papers

### Review
1. Xingchen Zhang, Ping Ye, Henry Leung, Ke Gong, Gang Xiao.  
	  **Object Fusion Tracking Based on Visible and Infrared Images: A Comprehensive Review**. **Information Fusion**, vol.63, pp.166-187,2020.[[paper][19]]


### 2021
#### Journal
1. Qin Xu, Yiming Mei, Jinpei Liu, Chenglong Li  
"Multimodal Cross-Layer Bilinear Pooling for RGBT Tracking", IEEE Transactions on Multimedia, 2021. [[Paper](https://ieeexplore.ieee.org/abstract/document/9340007?casa_token=2J66RsN_jAQAAAAA:f6O-OSYp3Hwco_zzTP7175Oq35qaFNRvgX29LqMfjfO7Ya4vAHCCkuNJabgtoOusYTaH89kB)]

2. Pengyu Zhang, Jie Zhao, Dong Wang, Huchuan Lu, Xiaoyun Yang  
"Jointly Modeling Motion and Appearance Cues for Robust RGB-T Tracking", IEEE TIP, Vol. 30, 2021. [[Paper](https://ieeexplore.ieee.org/abstract/document/9364880?casa_token=ETbE6iP5zpgAAAAA:KvjZeam43Lg-m1GdgIusD6_4nDNsNOn8pWCtel5W-vy4JVY3KfUm8QZsP3T-qR41CVLPV43Q)]

3. Yabin Zhu, Chenglong Li, Jin Tang, Bin Luo, Liang Wang.  
"RGBT Tracking by Trident Fusion Network", IEEE TCSVT, 2021.

4. Tianlu Zhang, Xueru Liu, Qiang Zhang, Jungong Han.  
"SiamCDA: Complementarity- and distractor-aware RGB-T tracking based on Siamese network", IEEE TCSVT, 2021.


#### arXiv
1. Jingchao Peng, Haitao Zhao, Zhengwei Hu, Yi Zhuang, Bofan Zhang.  
Siamese Infrared and Visible Light Fusion Network for RGB-T tracking, arXiv, 2021. [[Paper](https://arxiv.org/abs/2103.07302)]

### 2020
#### Journal
1. Xingchen Zhang, Ping Ye, Shengyun Peng, Jun Liu, Gang Xiao  
	  "DSiamMFT: An RGB-T fusion tracking method via dynamic Siamese networks using multi-layer feature fusion", Signal Processing: Image Communication, 2020. [[paper][20]]

2. Xingchen Zhang, Ping Ye, Henry Leung, Ke Gong, Gang Xiao.  
	  "Object Fusion Tracking Based on Visible and Infrared Images: A Comprehensive Review". Information Fusion, 2020.[[paper][29]] 
	 
3. Mingzheng Feng, Kechen Song, Yanyan Wang, Jie Liu, Yunhui Yan.  
	  "Learning Discriminative Update Adaptive Spatial-Temporal Regularized Correlation Filter for RGB-T Tracking", Journal of Visual Communication and Image Representation,2020.[[paper][24]]

4. Hui Zhang, Lei Zhang, Li Zhuo, Jing Zhang.  
	  "Object tracking in RGB-T videos using modal-aware attention network and competitive learning". Sensors, 2020. [[paper][26]]

5. Yabin Zhu, Chenglong Li, Jin Tang, Bin Luo.  
	  "Quality-aware Feature Aggregation Network for Robust RGBT Tracking". IEEE Transactions on Intelligent Vehicles, 2020. [[paper][27]]

6. Xiangyuan Lan, Mang Ye, Shengping Zhang, Huiyu Zhou, Pong C. Yuen.  
	  "Modality-correlation-aware sparse representation for RGB-infrared object tracking".Pattern Recognition Letters, 2020. [[paper][28]]
	  
7. Mengzheng Feng, Kechen Song, Yanyan Wang, Jie Liu, Yunhui Yan.  
"Learning Discriminative Update Adaptive Spatial-Temporal Regularized Correlation Filter for RGB-T Tracking", Journal of Visual Communication and Image Representation, Vol. 72, 2020.	  	  
	  
#### Conference
1. Chenglong Li, Lei Liu, Andong Lu, Qing Ji, and Jin Tang  
	  "Challenge-Aware RGBT Tracking". ECCV 2020. [[paper][22]]
2. Chaoqun Wang, Chunyan Xu, Zhen Cui, Ling Zhou, Tong Zhang, Xiaoya Zhang, Jian Yang  
	  "Cross-Modal Pattern-Propagation for RGB-T Tracking".CVPR 2020.[[paper][23]]	  
	  
	  
#### arXiv	  
1. Andong Lu, Cun Qian, Chenglong Li, Jin Tang, Liang Wang.  
     "Duality-Gated Mutual Condition Network for RGBT tracking", arXiv, 2020. [[Paper](https://arxiv.org/abs/2011.07188)]

2. Zhengzheng Tu, Chun Lin, Chenglong Li, Jin Tang, Bin Luo.  
	  "M5L: Multi-Modal Multi-Margin Metric Learning for RGBT Tracking". arXiv:2003.07650, 2020. [[paper][25]]

3. Andong Liu, Chenglong Li, Yuqing Yan, Jin Tang, Bin Luo.  
	"RGBT Tracking via Multi-Adapter Network with Hierarchical Divergence Loss". arXiv:2011.07189, 2020. [[paper](https://arxiv.org/abs/2011.07189)]
 

### 2019
#### Journal
1. Xiao Yun , Yanjing Sun , Xuanxuan Yang, and Nannan Lu  
	   "Discriminative fusion correlation learning for visible and infrared tracking." Mathematical Problems in Engineering, 2019. [[paper][34]]

2. Bin Kang , Dong Liang , Wan Ding, Huiyu Zhou, and Wei-Ping Zhu  
	  "Grayscale-Thermal Tracking via Inverse Sparse Representation-Based Collaborative Encoding." IEEE Transactions on Image Processing, 2019. [[paper][35]]


3. Chengwei Luo, Bin Suna, Ke Yanga, Taoran Lua, Wei-Chang Yeh  
	  "Thermal infrared and visible sequences fusion tracking based on a hybrid tracking framework with adaptive weighting scheme." Infrared Physics & Technology, 2019.[[paper][37]]
	  
4. Xiangyuan Lan, Wei Zhang, Shengping Zhang, Deepak Kumar Jain, Huiyu Zhou  
	 "Robust Multi-modality Anchor Graph-based Label Prediction for RGB-Infrared Tracking", IEEE Transactions on Industrial Informatics, 2019. [[paper][39]]

5. Xingchen Zhang, Ping Ye, Shengyun Peng, Jun Liu, Ke Gong, Gang Xiao  
	  "SiamFT: An RGB-infrared fusion tracking method via fully convolutional siamese networks." IEEE Access, 2019.[[paper][40]]
	  
6. Singh, Satbir, Arun Khosla, and Rajiv Kapoor.  
	  "Object Tracking with a Novel Visual-Thermal Sensor Fusion Method in Template Matching." International Journal of Image, Graphics and Signal Processing, 2019.[[paper][42]]

7. Chenglong Li, Xinyan Liang, Yijuan Lu, Nan Zhao, Jin Tang  
	  "RGB-T object tracking: Benchmark and baseline", Pattern Recognition, 2019. [[paper][43]]

8. Can-Long Zhang, Yan-Ping Tang, Zhi-Xin Lia, Zhi-Wen Wang  
	  "Joint spatiograms for multi-modality tracking with online update", Pattern Recognition Letters, 2019.[[paper][44]]

9. Xiangyuan Lan, Mang Ye, Rui Shan, Bineng Zhong, Deepak Kumar Jain, Huiyu Zhou  
	“Online non-negative multi-modality feature template learning for RGB-assisted infrared tracking”. IEEE Access, 2019. [[paper][45]]

10. Chengwei Luo, Bin Sun, Ke Yang, Taoran Lu, Wei-Chang Yeh.  
	  “Thermal infrared and visible sequences fusion tracking based on a hybrid tracking framework with adaptive weighting scheme”. Infrared Physics & Technology, 2019. [[paper][46]]

11. Sulan Zhai, Pengpeng Shao, Xinyan Liang, Xin Wang.  
	"Fast RGB-T Tracking via Cross-Modal Correlation Filters." Neurocomputing, 2019.[[paper][47]]

12. Xiangyuan Lan, Mang Ye, Rui Shao, Bineng Zhong, Pong C.Yuen, Huiyu Zhou.  
	  "Learning Modality-Consistency Feature Templates: A Robust RGB-Infrared Tracking System." IEEE Transactions on Industrial Electronics, 2019.[[paper][48]]

13. Chenglong Li, Chengli Zhu, Jian Zhang, Bin Luo, Xiaohao Wu, and Jin Tang.  
	  "Learning Local-Global Multi-Graph Descriptors for RGB-T Object Tracking". IEEE Transactions on Circuits and Systems for Video Technology, 2019.[[paper][49]]	  	  

#### Conference
1. Xingchen Zhang, Ping Ye, Dan Qiao, Junhao Zhao, Shengyun Peng, Gang Xiao  
	  "Object fusion tracking based on visible and infrared images using fully convolutional siamese networks." International Conference on Information Fusion (FUSION), 2019. [[paper][41]]

2. Chenglong Li, Andong Lu, Aihua Zheng, Zhengzheng Tu, Jin Tang  
	  "Multi-adapter rgbt tracking." ICCVW, 2019. [[paper][30]]

3. Matej Kristan et al.  
	  "The Seventh Visual Object Tracking VOT2019 Challenge Results", ICCVW, 2019. [[paper][31]]

4. Yuan Gao, Chenglong Li, Yabin Zhu, Jin Tang, Tao He, Futian Wang  
	  "Deep adaptive fusion network for high performance rgbt tracking." ICCVW, 2019. [[paper][32]]

5. Lichao Zhang, Martin Danelljan, Abel Gonzalez-Garcia, Joost van de Weijer, Fahad Shahbaz Khan  
	  "Multi-modal fusion for end-to-end rgb-t tracking." ICCVW. 2019. [[paper][33]]

6. Stephane Vujasinovic, Stefan Becker, Norbert Scherer-Negenborn, and Michael Arens  
	  "Impact of Fused Visible-Infrared Video Streams on Visual Tracking." Iberian Conference on Pattern Recognition and Image Analysis. 2019. [[paper][36]]

7. Yabin Zhu, Chenglong Li, Jin Tang, Bin Luo, Xiao Wang  
	  "Dense feature aggregation and pruning for rgbt tracking." **ACM MM**. 2019.[[paper][38]]

8. Rui Yang, Yabin Zhu, Xiao Wang, Chenglong Li \*, and Jin Tang.  
	  “Learning Target-oriented Dual Attention for Robust RGB-T Tracking”. IEEE International Conference on Image Processing (ICIP), 2019.[[paper][50]]

### 2018
#### Journal
1. Keyan Ren, Xiao Zhang, Yu Han, Yibin Hou.  
	   "Robust night target tracking via infrared and visible video fusion". Applications of Digital Image Processing, 2018. (asynchronous VI and IR videos)[[paper][51]]

2. Chenglong Li, Xiaohao Wu, Nan Zhao, Xiaochun Cao, and Jin Tang.  
	  "Fusing Two-Stream Convolutional Neural Networks for RGB-T Object Tracking". Neurocomputing (NEUCOM), 281: 78-85, 2018.[[paper][52]]

3. Chenglong Li, Chengli Zhu, Shaofei Zheng, Bin Luo, and Jin Tang.  
	  "Two-Stage Modality-Graphs Regularized Manifold Ranking for RGB-T Tracking". Signal Processing: Image Communication (SPIC), 68: 207-217, 2018. [[paper][53]]

4. Meng Ding, Yao Yuheng, Li Wei, Yunfeng Cao.  
	  "Visual tracking using Locality-constrained Linear Coding and saliency map for visible light and infrared image sequences". Signal Processing: Image Communication, 2018.[[paper][54]]



#### Conference
1. Xingming Zhang, Xuehan Zhang, Xuedan Du, Xiangming Zhou, Jun Yin.  
	 "Learning Multi-domain Convolutional Network for RGB-T Visual Tracking." CISP-BMEI, 2018. [[paper][55]]

2. Chenglong Li, Chengli Zhu, Yan Huang, Jin Tang, Liang Wang.  
	   "Cross-Modal Ranking with Soft Consistency and Noisy Labels for Robust RGB-T Tracking." **ECCV 2018**.[[paper][56]]  

3. Xiangyuan Lan, Mang Ye, Shengping Zhang, Pong C. Yuen.  
	   "Robust Collaborative Discriminative Learning for RGB-Infrared Tracking". **AAAI 2018**.

4. Yulong Wang, Chenglong Li, and Jin Tang.  
	“Learning Soft-Consistent Correlation Filters for RGB-T Object Tracking”. PRCV 2018.[[paper][57]]

5. Ningwen Xu, Gang Xiao, Xingchen Zhang, Durga Prasad Bavirisetti.  
	"Relative Object Tracking Algorithm Based on Convolutional Neural Network for Visible and Infrared Video Sequences". 4th International Conference on Virtual Reality, 2018. [[paper][58]]

6. Ningwen Xu, Gang Xiao, Fang He, Xingchen Zhang, Durga Prasad Bavirisetti.  
	"Object Tracking via Deep Multi-View Compressive Model for Visible and Infrared Sequences". Fusion 2018. [[paper][59]]

7. Chengwei Luo, Bin Sun, Qiao Deng, Zihao Wang, Dengwei Wang.  
	    "Comparison of Different Level Fusion Schemes for Infrared-Visible Object Tracking: An Experimental Survey". 2018 2nd International Conference on Robotics and Automation Sciences. [[paper][60]]

### 2017
#### Journal
1. Chenglong Li, Xiang Sun, Xiao Wang, Lei Zhang, and Jin Tang.  
	  "Grayscale-thermal Object Tracking via Multi-task Laplacian Sparse Representation". **IEEE Transactions on Systems, Man, and Cybernetics: Systems (T-SMCS)**, 47(4): 673-681, 2017.[[paper][61]]

#### Conference
1. Chenglong Li, Nan Zhao, Yijuan Lu, Chengli Zhu, and Jin Tang.  
	   "Weighted Sparse Representation Regularized Graph Learning for RGB-T Object Tracking". **ACM International Conference on Multimedia (ACM MM)**, 2017.

### 2016
#### Journal
1. Chenglong Li, Hui Cheng, Shiyi Hu, Xiaobai Liu, Jin Tang, Liang Lin.  
	    “Learning Collaborative Sparse Representation for Grayscale-Thermal Tracking”,  **IEEE Transactions on Image Processing**, 25(12): 5743-5756, 2016. [[paper][62]]

2. Xiao Yun, Zhongliang Jing, Bo Jin.
	"Visible and infrared tracking based on multi-view multi-kernel fusion model". Optical Review, 2016.[[paper][63]]

3. Xiao Yun, Zhongliang Jing, Gang Xiao, Bo Jin, Canlong Zhang.  
	 "A compressive tracking based on time-space Kalman fusion model". Science China Information Sciences, 2016.[[paper][64]]

4. Supriya Mangale, Madhuri Khambete.  
	 "Camouflaged target detection and tracking using thermal infrared and visible spectrum imaging". Advances in Intelligent Systems and Computing, 2016.[[paper][65]]

#### Conference
1. Chenglong Li, Shiyi Hu, Sihan Gao, and Jin Tang.  
	   "Real-time Grayscale-thermal Tracking  via Laplacian Sparse Representation". International Conference on Multimedia Modelling (MMM), Miami, 2016. [[paper][66]]

### Before 2016

- Erhan Gundogdu, Huseyin Ozkan, H. Seckin Demir, Hamza Ergezer, Erdem Akag¨und¨uz, S. Kubilay Pakin.  
	 "Comparison of infrared and visible imagery for object tracking: Toward trackers with superior IR performance". **CVPR 2015**. [[paper][67]]
- Alex Lipchen Chan, Stephen R. Schnelle.  
	 "Fusing concurrent visible and infrared videos for improved tracking performance". Optical Engineering, 2013.[[paper][68]]
- Huaping Liu, Fuchun Sun.  
	 "Fusion tracking in color and infrared images using joint sparse representation". Science China Information Sciences, 2012.[[paper][69]]
- Alex Lipchen Chan, Stephen R. Schnelle.  
	 "Target tracking using concurrent visible and infrared imageries". SPIE, 2012.[[paper][70]]
- Stephen R. Schnelle, Alex Lipchen Chan.  
	 "Enhanced target tracking through infrared-visible image fusion". Fusion 2011. [[paper][71]]
- K. Senthil Kumar1, G. Kavitha, R. Subramanian, G. Ramesh.  
	    "Visual and Thermal Image Fusion of UAV Based Target Tracking". Intech open, 2011. [[paper][72]]
- Huaping Liu, Fuchun Sun.  
- "Fusion tracking in color and infrared images using sequential belief propagation". Proceedings - IEEE International Conference on Robotics and Automation, 2008. [[paper][73]]


### Other papers
#### Multispectral person detection (may give some ideas to fusion tracking)
- Daniel K¨onig, Michael Adam, Christian Jarvers, Georg Layher, Heiko Neumann, and Michael Teutsch.  
	 "Fully Convolutional Region Proposal Networks for Multispectral Person Detection". **CVPR 2017**.


## Datasets and benchmark
- **GTOT**
	- Paper: Chenglong Li, Hui Cheng, Shiyi Hu, Xiaobai Liu, Jin Tang, Liang Lin.  
		“Learning Collaborative Sparse Representation for Grayscale-Thermal Tracking”,  IEEE Transactions on Image Processing (T-IP), 25(12): 5743-5756, 2016. [[paper][74]]
	- Download Link [[Google drive][75]] [[Baidu Cloud][76]][]()

- **RGBT210**
	- Paper: Chenglong Li, Nan Zhao, Yijuan Lu, Chenglin  Zhu, Jin Tang.  
		“Weighted Sparse Representation Regularized Graph Learning for RGB-T Object Tracking”, ACM International Conference on Multimedia (ACM MM), 2017. [[paper][78]]
	- Download Link [[Google drive][79]][[Baidu Cloud][80]]

- **RGBT234**
	- Paper: Chenglong Li, Xinyan Liang, Yijuan Lu, Nan Zhao, and Jin Tang.  
		“RGB-T Object Tracking:Benchmark and Baseline”, ArXiv, 2018. Submitted to Pattern Recognition (PR), 2019. [[paper][81]][[project][82]]
	- Download Link [[Google drive](https://drive.google.com/open?id=1ouNEptXOgRop4U7zYMK9zAp57SZ2XCNL)]

## Results
### GTOT
	Name       | PR   | SR   | Year | Author     |  Type    | FPS |
	FANet      | 88.5 | 69.8 | 2018 | Li et al.  | DL-based | 1.3 |
	SCCF       | 85   | 68.1 | 2018 | Li et al.  | CF-based | 50  |
	LGMG       | 82.9 | 65.5 | 2018 | Li et al.  |          |  7  |
	Cross-modal| 82.7 | 64.3 | 2018 | Li et al.  |          |  8  |
	Fast RGB-T | 77   | 63.2 | 2019 | Zhai et al.| CF-based | 227 |
	Weighted   | 85.12| 62.8 | 2017 | Li et al.  |          |  5  |
	Fusing two | 85.2 | 62.6 | 2018 | Li et al.  | DL-based | 15  |
	Two stage  | 84.2 | 62.2 | 2018 | Li et al.  |          | 7   |
	CSR        | 75   | 62   | 2016 | Li et al.  |          |     |

### RGBT210
	Name       | PR   | SR   | Year | Author     |  Type    | FPS |
	LGMG       | 71.1 | 46.8 | 2018 | Li et al.  |          |  7  |
	Cross-modal| 69.4 | 46.3 | 2018 | Li et al.  |          |  8  | 
	SiamFT     | 65.0 | 44.3 | 2019 |Zhang et al.| DL-bsed  | 25+ |
	Weighted   | 67.5 | 43.0 | 2017 | Li et al.  |          |  5  |  
	Fast RGB-T | 52.9 | 36.6 | 2019 | Zhai et al.| CF-based | 227 |
 
 
### RGBT234
	Name         | PR   | SR   | Year |Author       |  Type    | FPS |
	DAPNet       | 76.6 | 53.7 | 2019 | Li et al.   | DL-based |
	FANet        | 76.4 | 53.2 | 2018 | Li et al.   | DL-based | 1.3 |
	SGT          | 72.0 | 47.2 | 2018 | Li et al.   |          | 
	SiamFT       | 65.9 | 44.8 | 2019 | Zhang et al.| DL-based | 25+ |
	SiamFC_RGT   | 61.0 | 42.8 | 2019 | Zhang et al.| DL-based |     |  
	Multi-domain | 61.7 | 38.7 | 2018 | Zhang et al.| DL-based |     |

## VOT-RGBT Challenge
### 2019


[1]:	#Papers
[2]:	#Review
[3]:	#2020
[4]:	#2019
[5]:	#2018
[6]:	#2017
[7]:	#2016
[8]:	#before-2016
[9]:	#datasets-and-benchmark
[10]:	#gtot
[11]:	#rgbt210
[12]:	#rgbt234
[13]:	#results
[14]:	#gtot
[15]:	#rgbt210
[16]:	#rgbt234
[17]:	#vot-rgbt-challenge
[18]:	#2019
[19]:	https://www.sciencedirect.com/science/article/abs/pii/S1566253520302657
[20]:	https://www.sciencedirect.com/science/article/pii/S092359651930342X?casa_token=pMtdGjKWkCsAAAAA:_RXEPXWfbX5FH1gUZvxApXniBtffeYuXEXErbdWFao6GXUVGZCAU2lk3tTWjQ1UWv-e-NCTu0VE
[21]:	https://arxiv.org/abs/2007.02041
[22]:	https://arxiv.org/abs/2007.13143
[23]:	https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_Cross-Modal_Pattern-Propagation_for_RGB-T_Tracking_CVPR_2020_paper.html
[24]:	https://www.sciencedirect.com/science/article/pii/S1047320320301279
[25]:	https://arxiv.org/abs/2003.07650
[26]:	https://www.mdpi.com/1424-8220/20/2/393
[27]:	https://ieeexplore.ieee.org/abstract/document/9035457
[28]:	https://www.sciencedirect.com/science/article/pii/S0167865518307633
[29]:	https://www.sciencedirect.com/science/article/abs/pii/S1566253520302657
[30]:	https://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Li_Multi-Adapter_RGBT_Tracking_ICCVW_2019_paper.html
[31]:	https://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.html
[32]:	https://openaccess.thecvf.com/content_ICCVW_2019/html/VISDrone/Gao_Deep_Adaptive_Fusion_Network_for_High_Performance_RGBT_Tracking_ICCVW_2019_paper.html
[33]:	https://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Zhang_Multi-Modal_Fusion_for_End-to-End_RGB-T_Tracking_ICCVW_2019_paper.html
[34]:	https://www.hindawi.com/journals/mpe/2019/2437521/
[35]:	https://ieeexplore.ieee.org/abstract/document/8941283?casa_token=gAveIfzMFgwAAAAA:xyoJG66lidcT-mjeb5LAZGlqDUxiw3wGojnllmb-8ozUpyN8_I5ACcbBVMh0jqFyJ4T6674WFg
[36]:	https://link.springer.com/chapter/10.1007/978-3-030-31332-6_9
[37]:	https://www.sciencedirect.com/science/article/pii/S1350449519300258?casa_token=wwA_-yMpJuIAAAAA:cGizzRXPd4Skh5qMQDJWYrGOmbcXJguNwvHGRz3ZgWmiIF9-XtSqt8zHqEE1GwxUmYxL-BSXWJw
[38]:	https://dl.acm.org/doi/abs/10.1145/3343031.3350928?casa_token=wtIXVlNcxMIAAAAA:ZyFWe7PsZDK_NkkjJpuRcn-B1FgY6439IVGDzO6ocgNO83UTgg53AGwKIrbNGRcL0JNDm44bXEgeWQ
[39]:	https://ieeexplore.ieee.org/abstract/document/8868207?casa_token=vMG2PsIDfUsAAAAA:dBEVhbzhYmW1jUPEhc1g-nTYx1jhtanaEZwPW1lJfgKUyfA-lP2iNdg640J_GGO8tYGAD8UPLQ
[40]:	https://ieeexplore.ieee.org/abstract/document/8809774
[41]:	https://ieeexplore.ieee.org/abstract/document/9011253
[42]:	http://j.mecs-press.net/ijigsp/ijigsp-v11-n7/IJIGSP-V11-N7-3.pdf
[43]:	https://www.sciencedirect.com/science/article/pii/S0031320319302808?casa_token=GRBRep1oB_YAAAAA:dKR9RtnRVH-JEtkkLb7cdq3yHm__HrIM_2RafIKEUUxUzxy6vR1WEoKin5RKjICGNQPC_1Utc6I
[44]:	https://www.sciencedirect.com/science/article/pii/S0167865519300698?casa_token=Xqa9aVWLJjUAAAAA:S4bFTmJsHoWkQPaY8VmmGP4FvBEK1B0Mb3TL4Gn2tU-N2_hRCHsJ1sQldzN55FRoqntl6CdlFyw
[45]:	https://ieeexplore.ieee.org/document/8713854
[46]:	https://www.sciencedirect.com/science/article/pii/S1350449519300258
[47]:	https://www.sciencedirect.com/science/article/pii/S0925231219300347
[48]:	https://ieeexplore.ieee.org/document/8643077
[49]:	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8485393
[50]:	https://ieeexplore.ieee.org/abstract/document/8803528?casa_token=ldSH9UAz7n4AAAAA:2tfEmXqIQxABqG4y9ZidZ6SxAukd2si7QqkWQK6s4BS3acHySymAmkAbua5cfgsL6X0rZ6Hbvw
[51]:	https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10752/1075206/Robust-night-target-tracking-via-infrared-and-visible-video-fusion/10.1117/12.2320450.full?SSO=1
[52]:	https://www.sciencedirect.com/science/article/pii/S0925231217318271
[53]:	https://www.sciencedirect.com/science/article/pii/S0923596518304892
[54]:	https://www.sciencedirect.com/science/article/pii/S0923596518302510
[55]:	https://ieeexplore.ieee.org/abstract/document/8633180?casa_token=v0wpaxPWnZ8AAAAA:KAi5grxf4uXrR8n5yuMEIF2rZ7RqpbzAgUj_m1Yl7LU6fiSeQz3HGEcSoCGiklyxItC_0aMVjg
[56]:	https://openaccess.thecvf.com/content_ECCV_2018/html/Chenglong_Li_Cross-Modal_Ranking_with_ECCV_2018_paper.html
[57]:	https://link.springer.com/chapter/10.1007/978-3-030-03341-5_25
[58]:	https://dl.acm.org/doi/abs/10.1145/3198910.3198918?casa_token=tZLCeHyI8ikAAAAA:WtvIrmiSU0klvPDaKy2Qvj_IxGDu95iFj_2x7dRg8kMb53Qm4JwB7tPn3IED2MwXH-O7nipTuV1VPg
[59]:	https://ieeexplore.ieee.org/abstract/document/8455855
[60]:	https://ieeexplore.ieee.org/abstract/document/8443230?casa_token=pV9YwMG5qzcAAAAA:Jt0sp-Cgh9UsFlkR4L2dukLv_mByTNSCRQF5sac2rpY1M_8YS9K3J_lO2CGiBk3KOWMCqB6h-A
[61]:	https://link.springer.com/chapter/10.1007%2F978-3-319-27674-8_6
[62]:	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7577747
[63]:	https://link.springer.com/article/10.1007/s10043-015-0175-5
[64]:	https://link.springer.com/article/10.1007/s11432-015-5356-0
[65]:	https://link.springer.com/chapter/10.1007/978-3-319-47952-1_15
[66]:	https://link.springer.com/chapter/10.1007/978-3-319-27674-8_6
[67]:	https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W05/html/Gundogdu_Comparison_of_Infrared_2015_CVPR_paper.html
[68]:	https://www.spiedigitallibrary.org/journals/Optical-Engineering/volume-52/issue-1/017004/Fusing-concurrent-visible-and-infrared-videos-for-improved-tracking-performance/10.1117/1.OE.52.1.017004.full
[69]:	https://link.springer.com/article/10.1007/s11432-011-4536-9
[70]:	https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8392/83920P/Target-tracking-using-concurrent-visible-and-infrared-imageries/10.1117/12.918373.full
[71]:	https://ieeexplore.ieee.org/abstract/document/5977615?casa_token=UIdwjetC2fUAAAAA:khr5GRsV-BJViGVFPUNWGmww11Y3xijcqjHZ89nTmh6RTWgRPkPPAHTswL8swPsG8lm1F2jW5A
[72]:	https://books.google.co.uk/books?hl=zh-CN&lr=&id=qxOeDwAAQBAJ&oi=fnd&pg=PA307&dq=Visual+and+Thermal+Image+Fusion+of+UAV+Based+Target+Tracking&ots=xqq0NQMZRu&sig=7D_wlzuWekcGZD9RQjkE4gUUwzE&redir_esc=y#v=onepage&q=Visual%20and%20Thermal%20Image%20Fusion%20of%20UAV%20Based%20Target%20Tracking&f=false
[73]:	https://ieeexplore.ieee.org/abstract/document/4543550?casa_token=kxnMJX2K3RYAAAAA:gRab0taeYkDe3g2UhCmPzXnfKiEiQ53-Nfyglc7g5yz3Uz-q8sYEKN5iWyHuPHl3fBC6wr4XLA
[74]:	https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7577747
[75]:	https://docs.google.com/uc?id=0B-Z6TyBF2ceIZ0c1anVhaHQ3MFk&export=download
[76]:	https://pan.baidu.com/s/1QNidEo-HepRaS6OIZr7-Cw
[78]:	https://dl.acm.org/citation.cfm?id=3123289
[79]:	https://drive.google.com/file/d/0B3i2rdXLNbdUTkhsLVRwcTBTMlU/view
[80]:	https://pan.baidu.com/s/1qXDAq0O#list/path=%2F
[81]:	https://arxiv.org/pdf/1805.08982.pdf
[82]:	https://sites.google.com/view/ahutracking001/
[83]:	(https://drive.google.com/open?id=1ouNEptXOgRop4U7zYMK9zAp57SZ2XCNL)